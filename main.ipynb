{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7392d58c",
   "metadata": {},
   "source": [
    "# Iris dataset (scikit-learn) — quick analysis\n",
    "This file is a **percent-format notebook** (`# %%` cells). You can run it in VS Code / Cursor as a notebook.\n",
    "\n",
    "The analysis is structured as:\n",
    "- Import and dependency checks\n",
    "- Loading the Iris dataset into a typed `DataFrame`\n",
    "- Quick exploratory data analysis (EDA)\n",
    "- Train/test split\n",
    "- Model comparison with cross-validation\n",
    "- Final evaluation of the best model...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb588f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c394176",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import math\n",
    "from typing import Final, Iterable, Sequence\n",
    "\n",
    "\n",
    "def _require_package_imports() -> None:\n",
    "    \"\"\"\n",
    "    Import required packages and raise a helpful error if missing.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import matplotlib.pyplot as _plt  # noqa: F401\n",
    "        import numpy as _np  # noqa: F401\n",
    "        import pandas as _pd  # noqa: F401\n",
    "        import seaborn as _sns  # noqa: F401\n",
    "        import sklearn  # noqa: F401\n",
    "        import sklearn.datasets as _datasets  # noqa: F401\n",
    "        import sklearn.discriminant_analysis as _discriminant_analysis  # noqa: F401\n",
    "        import sklearn.ensemble as _ensemble  # noqa: F401\n",
    "        import sklearn.linear_model as _linear_model  # noqa: F401\n",
    "        import sklearn.metrics as _metrics  # noqa: F401\n",
    "        import sklearn.model_selection as _model_selection  # noqa: F401\n",
    "        import sklearn.pipeline as _pipeline  # noqa: F401\n",
    "        import sklearn.preprocessing as _preprocessing  # noqa: F401\n",
    "        import sklearn.svm as _svm  # noqa: F401\n",
    "    except ImportError as exc:  # pragma: no cover\n",
    "        raise ImportError(\n",
    "            \"Missing one or more required packages. Install them with:\\n\"\n",
    "            \"  pip install -U scikit-learn pandas matplotlib numpy seaborn\\n\"\n",
    "            f\"Original error: {exc}\"\n",
    "        ) from exc\n",
    "\n",
    "\n",
    "_require_package_imports()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7c752e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED: Final[int] = 42\n",
    "TEST_SIZE: Final[float] = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcbffdc",
   "metadata": {},
   "source": [
    "## Load Iris dataset into a typed DataFrame\n",
    "\n",
    "In this section we load the classic Iris dataset from `sklearn.datasets`,\n",
    "convert it into a `pandas.DataFrame`, and give the feature columns clear,\n",
    "Python-friendly names. We also keep the target labels and their human-readable\n",
    "class names together in a small immutable data container (`IrisData`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886e213a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class IrisData:\n",
    "    features: pd.DataFrame\n",
    "    target: pd.Series\n",
    "    target_names: tuple[str, ...]\n",
    "\n",
    "\n",
    "def load_iris_dataframe() -> IrisData:\n",
    "    iris = datasets.load_iris(as_frame=True)\n",
    "    if iris.frame is None:\n",
    "        raise ValueError(\"Expected Iris dataset to include a frame.\")\n",
    "\n",
    "    features_df = iris.frame.drop(columns=[iris.target.name])\n",
    "    target_series = iris.frame[iris.target.name]\n",
    "\n",
    "    features_df = features_df.rename(\n",
    "        columns={\n",
    "            \"sepal length (cm)\": \"sepal_length_cm\",\n",
    "            \"sepal width (cm)\": \"sepal_width_cm\",\n",
    "            \"petal length (cm)\": \"petal_length_cm\",\n",
    "            \"petal width (cm)\": \"petal_width_cm\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if not isinstance(iris.target_names, np.ndarray):\n",
    "        raise TypeError(\"Expected iris.target_names to be a numpy array.\")\n",
    "\n",
    "    target_names = tuple(str(x) for x in iris.target_names.tolist())\n",
    "\n",
    "    return IrisData(\n",
    "        features=features_df,\n",
    "        target=target_series.astype(\"int64\"),\n",
    "        target_names=target_names,\n",
    "    )\n",
    "\n",
    "\n",
    "iris_data = load_iris_dataframe()\n",
    "iris_data.features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e34d77",
   "metadata": {},
   "source": [
    "## Quick EDA\n",
    "\n",
    "Here we create a copy of the feature data with a readable `species` column,\n",
    "compute summary statistics, and look at simple distributions and relationships\n",
    "between features. The correlation heatmap and scatter-matrix plots help you\n",
    "see how sepal and petal measurements relate to each other and to the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a03342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = iris_data.features.copy()\n",
    "df[\"species\"] = iris_data.target.map(\n",
    "    {idx: name for idx, name in enumerate(iris_data.target_names)}\n",
    ")\n",
    "\n",
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d350608",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=df[\"species\"], columns=\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f54020c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = iris_data.features.corr(numeric_only=True)\n",
    "fig, ax = plt.subplots(figsize=(6.5, 5.0))\n",
    "im = ax.imshow(corr.values, vmin=-1.0, vmax=1.0, cmap=\"coolwarm\")\n",
    "ax.set_xticks(range(len(corr.columns)))\n",
    "ax.set_yticks(range(len(corr.columns)))\n",
    "ax.set_xticklabels(corr.columns, rotation=45, ha=\"right\")\n",
    "ax.set_yticklabels(corr.columns)\n",
    "ax.set_title(\"Feature correlation (Pearson)\")\n",
    "fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945c6429",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = pd.plotting.scatter_matrix(\n",
    "    df[[\"sepal_length_cm\", \"sepal_width_cm\", \"petal_length_cm\", \"petal_width_cm\"]],\n",
    "    figsize=(9, 9),\n",
    "    diagonal=\"kde\",\n",
    "    c=iris_data.target,\n",
    "    cmap=\"viridis\",\n",
    "    alpha=0.8,\n",
    ")\n",
    "plt.suptitle(\"Scatter matrix (colored by class)\", y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4370b4de",
   "metadata": {},
   "source": [
    "### Feature distributions by species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261b705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "feature_cols = [\"sepal_length_cm\", \"sepal_width_cm\", \"petal_length_cm\", \"petal_width_cm\"]\n",
    "colors_map = {\n",
    "    iris_data.target_names[0]: \"#440154\",\n",
    "    iris_data.target_names[1]: \"#31688e\",\n",
    "    iris_data.target_names[2]: \"#35b779\",\n",
    "}\n",
    "\n",
    "for idx, feature in enumerate(feature_cols):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    for species in iris_data.target_names:\n",
    "        species_data = df[df[\"species\"] == species][feature]\n",
    "        ax.hist(\n",
    "            species_data,\n",
    "            alpha=0.6,\n",
    "            label=species,\n",
    "            bins=15,\n",
    "            color=colors_map[species],\n",
    "            edgecolor=\"black\",\n",
    "        )\n",
    "    ax.set_xlabel(feature.replace(\"_\", \" \").title())\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "    ax.set_title(f\"Distribution of {feature.replace('_', ' ').title()}\")\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5451e5c5",
   "metadata": {},
   "source": [
    "### Box plots: Feature distributions by species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55be51fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "for idx, feature in enumerate(feature_cols):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    data_by_species = [\n",
    "        df[df[\"species\"] == species][feature].values\n",
    "        for species in iris_data.target_names\n",
    "    ]\n",
    "    bp = ax.boxplot(\n",
    "        data_by_species,\n",
    "        labels=iris_data.target_names,\n",
    "        patch_artist=True,\n",
    "        showmeans=True,\n",
    "    )\n",
    "    for patch, color in zip(bp[\"boxes\"], [colors_map[s] for s in iris_data.target_names]):\n",
    "        patch.set_facecolor(color)\n",
    "        patch.set_alpha(0.7)\n",
    "    ax.set_ylabel(feature.replace(\"_\", \" \").title())\n",
    "    ax.set_title(f\"Box plot: {feature.replace('_', ' ').title()}\")\n",
    "    ax.grid(alpha=0.3, axis=\"y\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c47ff3",
   "metadata": {},
   "source": [
    "### Violin plots: Feature distributions by species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ebe413",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "for idx, feature in enumerate(feature_cols):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    sns.violinplot(\n",
    "        data=df,\n",
    "        x=\"species\",\n",
    "        y=feature,\n",
    "        ax=ax,\n",
    "        palette=[colors_map[s] for s in iris_data.target_names],\n",
    "        inner=\"quart\",\n",
    "    )\n",
    "    ax.set_title(f\"Violin plot: {feature.replace('_', ' ').title()}\")\n",
    "    ax.set_xlabel(\"Species\")\n",
    "    ax.set_ylabel(feature.replace(\"_\", \" \").title())\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7c9f7a",
   "metadata": {},
   "source": [
    "### Pairwise feature comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17585916",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "pair_combinations = [\n",
    "    (\"sepal_length_cm\", \"sepal_width_cm\"),\n",
    "    (\"petal_length_cm\", \"petal_width_cm\"),\n",
    "    (\"sepal_length_cm\", \"petal_length_cm\"),\n",
    "    (\"sepal_width_cm\", \"petal_width_cm\"),\n",
    "    (\"sepal_length_cm\", \"petal_width_cm\"),\n",
    "    (\"sepal_width_cm\", \"petal_length_cm\"),\n",
    "]\n",
    "\n",
    "for idx, (feat_x, feat_y) in enumerate(pair_combinations):\n",
    "    ax = axes[idx // 3, idx % 3]\n",
    "    for species in iris_data.target_names:\n",
    "        species_df = df[df[\"species\"] == species]\n",
    "        ax.scatter(\n",
    "            species_df[feat_x],\n",
    "            species_df[feat_y],\n",
    "            label=species,\n",
    "            alpha=0.7,\n",
    "            s=60,\n",
    "            color=colors_map[species],\n",
    "            edgecolors=\"black\",\n",
    "            linewidth=0.5,\n",
    "        )\n",
    "    ax.set_xlabel(feat_x.replace(\"_\", \" \").title())\n",
    "    ax.set_ylabel(feat_y.replace(\"_\", \" \").title())\n",
    "    ax.set_title(f\"{feat_x.replace('_', ' ').title()} vs {feat_y.replace('_', ' ').title()}\")\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb12b53",
   "metadata": {},
   "source": [
    "### PCA 2D projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f50697",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2, random_state=RANDOM_SEED)\n",
    "X_pca = pca.fit_transform(iris_data.features)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "for idx, species in enumerate(iris_data.target_names):\n",
    "    mask = iris_data.target == idx\n",
    "    ax.scatter(\n",
    "        X_pca[mask, 0],\n",
    "        X_pca[mask, 1],\n",
    "        label=species,\n",
    "        alpha=0.7,\n",
    "        s=80,\n",
    "        color=colors_map[species],\n",
    "        edgecolors=\"black\",\n",
    "        linewidth=0.5,\n",
    "    )\n",
    "\n",
    "variance_explained = pca.explained_variance_ratio_\n",
    "ax.set_xlabel(f\"First Principal Component ({variance_explained[0]:.1%} variance)\")\n",
    "ax.set_ylabel(f\"Second Principal Component ({variance_explained[1]:.1%} variance)\")\n",
    "ax.set_title(\"PCA 2D Projection of Iris Features\")\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a97180",
   "metadata": {},
   "source": [
    "## Train/test split\n",
    "\n",
    "We split the data into train and test sets using a **stratified** split so\n",
    "that each Iris species keeps roughly the same proportion in both sets.\n",
    "The train set is used for cross-validation and model fitting; the test set\n",
    "is held back for the final, unbiased evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db502fa9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris_data.features,\n",
    "    iris_data.target,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=RANDOM_SEED,\n",
    "    stratify=iris_data.target,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4b13c8",
   "metadata": {},
   "source": [
    "## Model comparison with cross-validation\n",
    "We'll compare a few standard classifiers:\n",
    "- Logistic Regression (with scaling)\n",
    "- SVM RBF (with scaling)\n",
    "- LDA\n",
    "- Random Forest\n",
    "\n",
    "Each model is evaluated with **5-fold stratified cross-validation** on the\n",
    "training split. We compute the mean and standard deviation of the accuracy\n",
    "scores so you can see both central performance and variability across folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e694679f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_and_std(scores: Sequence[float]) -> tuple[float, float]:\n",
    "    if len(scores) == 0:\n",
    "        raise ValueError(\"scores must be non-empty.\")\n",
    "    mean = float(np.mean(scores))\n",
    "    std = float(np.std(scores, ddof=1)) if len(scores) > 1 else 0.0\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "models: dict[str, object] = {\n",
    "    \"logreg\": Pipeline(\n",
    "        steps=[\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"clf\", LogisticRegression(max_iter=2000, random_state=RANDOM_SEED)),\n",
    "        ]\n",
    "    ),\n",
    "    \"svm_rbf\": Pipeline(\n",
    "        steps=[\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"clf\", SVC(kernel=\"rbf\", gamma=\"scale\", C=1.0, random_state=RANDOM_SEED)),\n",
    "        ]\n",
    "    ),\n",
    "    \"lda\": LinearDiscriminantAnalysis(),\n",
    "    \"rf\": RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        random_state=RANDOM_SEED,\n",
    "    ),\n",
    "}\n",
    "\n",
    "rows: list[dict[str, float | str]] = []\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=cv, scoring=\"accuracy\")\n",
    "    mean, std = mean_and_std(scores.tolist())\n",
    "    rows.append({\"model\": name, \"cv_mean_accuracy\": mean, \"cv_std\": std})\n",
    "\n",
    "results = pd.DataFrame(rows).sort_values(\"cv_mean_accuracy\", ascending=False)\n",
    "results.reset_index(drop=True, inplace=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1694a5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7.0, 3.8))\n",
    "ax.bar(results[\"model\"], results[\"cv_mean_accuracy\"], yerr=results[\"cv_std\"], capsize=6)\n",
    "ax.set_ylim(0.0, 1.05)\n",
    "ax.set_title(\"Cross-validated accuracy (train split only)\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f51656",
   "metadata": {},
   "source": [
    "## Fit best model and evaluate on test set\n",
    "\n",
    "After comparing models on the train split, we pick the one with the highest\n",
    "cross-validated accuracy, fit it on the full training data, and then evaluate\n",
    "it once on the held-out test set. The classification report and confusion\n",
    "matrix show per-class precision, recall, F1-score, and where misclassifications\n",
    "occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab42640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = str(results.iloc[0][\"model\"])\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61483036",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"Best model:\", best_model_name)\n",
    "print()\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test,\n",
    "        y_pred,\n",
    "        target_names=list(iris_data.target_names),\n",
    "        digits=3,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccf20b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5.6, 4.6))\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    display_labels=list(iris_data.target_names),\n",
    "    cmap=\"Blues\",\n",
    "    ax=ax,\n",
    "    colorbar=False,\n",
    ")\n",
    "ax.set_title(f\"Confusion matrix — {best_model_name}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fcec22",
   "metadata": {},
   "source": [
    "### Feature importance (if Random Forest is used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb7bec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_model_name == \"rf\" or (\n",
    "    hasattr(best_model, \"named_steps\")\n",
    "    and \"clf\" in best_model.named_steps\n",
    "    and hasattr(best_model.named_steps[\"clf\"], \"feature_importances_\")\n",
    "):\n",
    "    if hasattr(best_model, \"feature_importances_\"):\n",
    "        importances = best_model.feature_importances_\n",
    "    elif hasattr(best_model.named_steps[\"clf\"], \"feature_importances_\"):\n",
    "        importances = best_model.named_steps[\"clf\"].feature_importances_\n",
    "    else:\n",
    "        importances = None\n",
    "\n",
    "    if importances is not None:\n",
    "        feature_names = list(iris_data.features.columns)\n",
    "        importance_df = pd.DataFrame(\n",
    "            {\"feature\": feature_names, \"importance\": importances}\n",
    "        ).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        bars = ax.barh(\n",
    "            importance_df[\"feature\"],\n",
    "            importance_df[\"importance\"],\n",
    "            color=\"#31688e\",\n",
    "            edgecolor=\"black\",\n",
    "        )\n",
    "        ax.set_xlabel(\"Feature Importance\")\n",
    "        ax.set_title(f\"Feature Importance — {best_model_name}\")\n",
    "        ax.grid(alpha=0.3, axis=\"x\")\n",
    "        for i, (idx, row) in enumerate(importance_df.iterrows()):\n",
    "            ax.text(\n",
    "                row[\"importance\"] + 0.01,\n",
    "                i,\n",
    "                f\"{row['importance']:.3f}\",\n",
    "                va=\"center\",\n",
    "                fontweight=\"bold\",\n",
    "            )\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aec6857",
   "metadata": {},
   "source": [
    "### Model comparison: Detailed CV scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1ffdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_detailed_scores: dict[str, list[float]] = {}\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=cv, scoring=\"accuracy\")\n",
    "    cv_detailed_scores[name] = scores.tolist()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "positions = np.arange(len(models))\n",
    "width = 0.15\n",
    "\n",
    "for fold_idx in range(5):\n",
    "    fold_scores = [cv_detailed_scores[name][fold_idx] for name in models.keys()]\n",
    "    offset = (fold_idx - 2) * width\n",
    "    ax.bar(\n",
    "        positions + offset,\n",
    "        fold_scores,\n",
    "        width,\n",
    "        label=f\"Fold {fold_idx + 1}\",\n",
    "        alpha=0.8,\n",
    "    )\n",
    "\n",
    "ax.set_xlabel(\"Model\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_title(\"Cross-validation scores per fold for each model\")\n",
    "ax.set_xticks(positions)\n",
    "ax.set_xticklabels(list(models.keys()))\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3, axis=\"y\")\n",
    "ax.set_ylim(0.0, 1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bc113c",
   "metadata": {},
   "source": [
    "### Prediction distribution visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1f588d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "true_counts = pd.Series(y_test).value_counts().sort_index()\n",
    "pred_counts = pd.Series(y_pred).value_counts().sort_index()\n",
    "\n",
    "x_pos = np.arange(len(iris_data.target_names))\n",
    "width = 0.35\n",
    "\n",
    "axes[0].bar(\n",
    "    x_pos - width / 2,\n",
    "    [true_counts.get(i, 0) for i in range(len(iris_data.target_names))],\n",
    "    width,\n",
    "    label=\"True\",\n",
    "    color=\"#35b779\",\n",
    "    alpha=0.8,\n",
    "    edgecolor=\"black\",\n",
    ")\n",
    "axes[0].bar(\n",
    "    x_pos + width / 2,\n",
    "    [pred_counts.get(i, 0) for i in range(len(iris_data.target_names))],\n",
    "    width,\n",
    "    label=\"Predicted\",\n",
    "    color=\"#31688e\",\n",
    "    alpha=0.8,\n",
    "    edgecolor=\"black\",\n",
    ")\n",
    "axes[0].set_xlabel(\"Species\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "axes[0].set_title(\"True vs Predicted class distribution (test set)\")\n",
    "axes[0].set_xticks(x_pos)\n",
    "axes[0].set_xticklabels(iris_data.target_names)\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3, axis=\"y\")\n",
    "\n",
    "correct_mask = y_test == y_pred\n",
    "axes[1].pie(\n",
    "    [correct_mask.sum(), (~correct_mask).sum()],\n",
    "    labels=[\"Correct\", \"Incorrect\"],\n",
    "    autopct=\"%1.1f%%\",\n",
    "    colors=[\"#35b779\", \"#e63946\"],\n",
    "    startangle=90,\n",
    "    explode=(0.05, 0.05),\n",
    ")\n",
    "axes[1].set_title(f\"Prediction accuracy breakdown — {best_model_name}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bbcced",
   "metadata": {},
   "source": [
    "### Feature correlation with target (class separation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1bca33",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "feature_means_by_class = []\n",
    "for species_idx, species_name in enumerate(iris_data.target_names):\n",
    "    species_mask = iris_data.target == species_idx\n",
    "    means = iris_data.features[species_mask].mean().values\n",
    "    feature_means_by_class.append(means)\n",
    "\n",
    "means_array = np.array(feature_means_by_class)\n",
    "im = ax.imshow(means_array, cmap=\"viridis\", aspect=\"auto\")\n",
    "ax.set_yticks(range(len(iris_data.target_names)))\n",
    "ax.set_yticklabels(iris_data.target_names)\n",
    "ax.set_xticks(range(len(feature_cols)))\n",
    "ax.set_xticklabels([f.replace(\"_\", \" \").title() for f in feature_cols], rotation=45, ha=\"right\")\n",
    "ax.set_title(\"Mean feature values by species (heatmap)\")\n",
    "cbar = fig.colorbar(im, ax=ax)\n",
    "cbar.set_label(\"Mean value\")\n",
    "\n",
    "for i in range(len(iris_data.target_names)):\n",
    "    for j in range(len(feature_cols)):\n",
    "        text = ax.text(\n",
    "            j,\n",
    "            i,\n",
    "            f\"{means_array[i, j]:.2f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            color=\"white\" if means_array[i, j] < means_array.mean() else \"black\",\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2b9889",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Notes\n",
    "- Iris is an easy dataset; you should expect high accuracy.\n",
    "- The visualizations show clear separation between species, especially in petal measurements.\n",
    "- PCA shows that most variance can be captured in 2 dimensions, explaining the high model performance."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py:percent",
   "main_language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
