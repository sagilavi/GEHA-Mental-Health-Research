{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d84187a6",
   "metadata": {},
   "source": [
    "# Iris dataset (scikit-learn) — quick analysis\n",
    "This file is a **percent-format notebook** (`# %%` cells). You can run it in VS Code / Cursor as a notebook.\n",
    "\n",
    "The analysis is structured as:\n",
    "- Import and dependency checks\n",
    "- Loading the Iris dataset into a typed `DataFrame`\n",
    "- Quick exploratory data analysis (EDA)\n",
    "- Train/test split\n",
    "- Model comparison with cross-validation\n",
    "- Final evaluation of the best model...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a24179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bc3be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "import warnings\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import List, Optional, Tuple, Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pdb\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any\n",
    "\n",
    "from Utilities import (\n",
    "    HEB_NIQQUD,\n",
    "    SPACE_NORMALIZE,\n",
    "    SENSITIVE_TERMS,\n",
    "    ensure_datetime,\n",
    "    load_data,\n",
    "    mask_sensitive,\n",
    "    normalize_hebrew,\n",
    "    prepare_labels,\n",
    "    preprocess_df,\n",
    "    temporal_split,\n",
    ")\n",
    "from Classes import ColumnSelector, ClinicalFeatureExtractor\n",
    "from Models import  build_vectorizer, build_model,train_with_cv,eval_probs,predict_proba_safe\n",
    "from Graphics import eval_slices, drift_top_terms, top_coefficients, plot_aupr_per_class\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    average_precision_score,\n",
    "    brier_score_loss,\n",
    "    precision_recall_curve,\n",
    "    classification_report,\n",
    ")\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, clone\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2809b329",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# ==================== TRAINING CONFIGURATION ====================\n",
    "# Central configuration for all ML pipeline hyperparameters.\n",
    "# Edit this section to change all training behavior.\n",
    "# ================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cf0281",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "TRAINING_CONFIG = {\n",
    "    # Vectorizer hyperparameters\n",
    "    \"vectorizer\": {\n",
    "        \"word_ngram_range\": (1, 2),  # Word n-gram range (min, max)\n",
    "        \"word_max_features\": 5000,   # Maximum word features\n",
    "        \"char_ngram_range\": (3, 5),  # Character n-gram range (min, max)\n",
    "        \"char_max_features\": 2500,   # Maximum character features\n",
    "        \"use_char\": False,            # Enable character n-grams\n",
    "        \"min_df\": 2,                 # Minimum document frequency for TF-IDF\n",
    "    },\n",
    "    \n",
    "    # Grid search hyperparameter grids\n",
    "    \"grid_search\": {\n",
    "        \"word_ngram_range_grid\": [(1, 1), (1, 2)],  # Grid for word n-gram range\n",
    "        \"word_max_features_grid\": [75, 100, 125, 150, 200, 300, 400, 500, 600, 700, 1000],  # Grid for word max_features\n",
    "        \"char_ngram_range_grid\": [(3, 5)],  # Grid for char n-gram range\n",
    "        \"char_max_features_grid\": [2000, 5000],  # Grid for char max_features\n",
    "        \"C_grid\": [  0.003, 0.01, 0.03, 0.1, 0.3, 0.5, 0.7, 0.9, 1.0,1.3],  # Regularization C values\n",
    "    },\n",
    "    \n",
    "    # Model hyperparameters\n",
    "    \"model\": {\n",
    "        \"max_iter\": 2000,            # Maximum iterations for LogisticRegression\n",
    "        \"solver\": \"saga\",            # Solver for LogisticRegression\n",
    "        \"class_weight_balanced\": True,  # Use balanced class weights\n",
    "        \"random_state\": 42,          # Random seed for reproducibility\n",
    "        \"calibrate\": True,           # Enable probability calibration\n",
    "        \"calib_method\": \"sigmoid\",   # Calibration method (\"sigmoid\" or \"isotonic\")\n",
    "        \"calib_cv\": 5,               # Cross-validation folds for calibration\n",
    "    },\n",
    "    \n",
    "    # Cross-validation hyperparameters\n",
    "    \"cv\": {\n",
    "        \"n_splits\": 5,               # Number of CV folds\n",
    "        \"shuffle\": True,              # Shuffle data before splitting\n",
    "        \"random_state\": 42,          # Random seed for CV splits\n",
    "        \"scoring\": \"f1_macro\",       # Scoring metric for GridSearchCV\n",
    "        \"n_jobs\": -1,                # Number of parallel jobs (-1 = all cores)\n",
    "        \"verbose\": 1,                # Verbosity level for GridSearchCV\n",
    "    },\n",
    "}\n",
    "\n",
    "# Other constants (not part of training config)\n",
    "MultyLablelMinPredictScoreForEval = 0.5\n",
    "CUTOFF = pd.Timestamp(\"2023-10-07\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869a20c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------ Utilities, data handling, split logic, and labels ------------------\n",
    "# Implementations for these live in `Utilities.py` and are imported above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6443ea75",
   "metadata": {},
   "source": [
    "Explain a bit what is happening here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773ab63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------ Vectorizers ------------------\n",
    "# ------------------ Model ------------------\n",
    "# ------------------ Training with CV ------------------\n",
    "# ------------------ Evaluation ------------------\n",
    "# ------------------ Drift/Explainability ------------------\n",
    "# ------------------ Lock feature space for drift/explainability ------------------\n",
    "# ------------------ Model comparison: Detailed CV scores ------------------\n",
    "# ------------------ Prepare post labels in the pre-learned class space ------------------\n",
    "# ------------------ Fit a clean vectorizer on all pre text to get stable feature names for analyses ------------------\n",
    "# ------------------ Detailed CV scores ------------------\n",
    "# ------------------ Prepare post labels in the pre-learned class space ------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca12259b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "340bed4f",
   "metadata": {},
   "source": [
    "### Feature distributions by species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e428a6f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f1a19e6",
   "metadata": {},
   "source": [
    "Explain a bit what is happening here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318e0fd4",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Explain a bit what is happening here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23758e5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# === Step 1: Parse CLI arguments ============================================================\n",
    "p = argparse.ArgumentParser(description=\"Hebrew clinical text classification pipeline.\")\n",
    "\n",
    "p.add_argument(\n",
    "    \"--data\",\n",
    "    default=r\"C:\\Users\\sagil\\GEAH\\MockDataSatatus.csv\",\n",
    "    help=\"Path to CSV or Parquet with id,text,diagnosis,date,soldier_flag\",\n",
    ")\n",
    "\n",
    "p.add_argument(\"--multilabel\", action=\"store_true\", default=False, help=\"Treat diagnosis as multi-label string\")\n",
    "p.add_argument(\"--base_model\", choices=[\"logreg\", \"linearsvc\"], default=\"logreg\")\n",
    "p.add_argument(\"--use_char\", action=\"store_true\", default=False, help=\"Add char n-grams 3-5\")\n",
    "p.add_argument(\"--max_features_word\", type=int, default=5000)\n",
    "p.add_argument(\"--max_features_char\", type=int, default=2500)\n",
    "p.add_argument(\"--ngram_word_max\", type=int, default=2)\n",
    "p.add_argument(\"--no_calibrate\", action=\"store_true\", default=False, help=\"Disable probability calibration\")\n",
    "p.add_argument(\"--output_dir\", default=r\"C:\\Users\\sagil\\GEAH\\.venv\\MainMLPipeline\\output\\sandboxoutput\", help=\"Directory to write JSON artifacts\")\n",
    "p.add_argument(\"--mask_sensitive_test\", action=\"store_true\", default=False, help=\"Run masking robustness test on post split\")\n",
    "\n",
    "if \"ipykernel\" in sys.modules:\n",
    "    args = p.parse_args([])\n",
    "else:\n",
    "    args = p.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01172dc1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "# === Step 2: Ensure output directory exists ================================================\n",
    "os.makedirs(args.output_dir, exist_ok=True)\n",
    "graphs_dir = os.path.join(args.output_dir, \"graphs\")\n",
    "os.makedirs(graphs_dir, exist_ok=True)\n",
    "\n",
    "# === Step 3: Load & preprocess raw data ====================================================\n",
    "# - Normalizes Hebrew text, coerces date, validates schema, boolean soldier_flag\n",
    "df = load_data(args.data)\n",
    "df = preprocess_df(df)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32ee8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 4: Temporal split (train before 2023-10-07; evaluate on/after) ===================\n",
    "pre, post = temporal_split(df)\n",
    "if len(pre) == 0 or len(post) == 0:\n",
    "    # We require both sides to exist to avoid leakage and to test generalization post-cutoff\n",
    "    print(\"ERROR: Pre or Post split empty.\", file=sys.stderr)\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919ff1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Step 5: Encode labels on pre only =====================================================\n",
    "# - Prevents peeking at post distribution/classes during training\n",
    "Y_pre, enc, classes = prepare_labels(pre[\"diagnosis\"], multilabel=args.multilabel)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518385b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 6: Define vectorizer & model =====================================================\n",
    "# - Word n-grams + optional char n-grams; linear model with optional calibration\n",
    "# Override config with CLI args if provided\n",
    "vec_config = TRAINING_CONFIG[\"vectorizer\"].copy()\n",
    "if hasattr(args, \"max_features_word\") and args.max_features_word:\n",
    "    vec_config[\"word_max_features\"] = args.max_features_word\n",
    "if hasattr(args, \"ngram_word_max\") and args.ngram_word_max:\n",
    "    vec_config[\"word_ngram_range\"] = (1, args.ngram_word_max)\n",
    "if hasattr(args, \"use_char\"):\n",
    "    vec_config[\"use_char\"] = args.use_char\n",
    "if hasattr(args, \"max_features_char\") and args.max_features_char:\n",
    "    vec_config[\"char_max_features\"] = args.max_features_char\n",
    "\n",
    "vec = build_vectorizer(config=vec_config)\n",
    "\n",
    "model_config = TRAINING_CONFIG[\"model\"].copy()\n",
    "if hasattr(args, \"no_calibrate\"):\n",
    "    model_config[\"calibrate\"] = not args.no_calibrate\n",
    "\n",
    "model = build_model(\n",
    "    base_model=args.base_model,\n",
    "    multilabel=args.multilabel,\n",
    "    config=model_config,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71fc764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 7: Cross-validated training on pre ===============================================\n",
    "# - Small grid over vectorizer and C; macro-F1 scoring; refit best pipeline\n",
    "\n",
    "\n",
    "print(\"args.multilabel:\", args.multilabel)\n",
    "#print(\"Y_pre shape:\", getattr(Y_pre, \"shape\", None))\n",
    "\n",
    "best, info = train_with_cv(\n",
    "    pre[\"text\"], Y_pre, vec, model, classes, args.base_model, args.multilabel,\n",
    "    config=TRAINING_CONFIG\n",
    ")\n",
    "\n",
    "print(\"\\n=== Grid Search Best Parameters ===\")\n",
    "for param, value in info[\"best_params\"].items():\n",
    "    print(f\"{param}: {value}\")\n",
    "print(f\"Best CV Score (f1_macro): {info['best_score_macro_f1']:.4f}\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "with open(os.path.join(args.output_dir, \"cv_best.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(info, f, ensure_ascii=False, indent=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2187b443",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5422aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 8: Lock feature space for drift/explainability ===================================\n",
    "# - Fit a clean vectorizer on all pre text to get stable feature names for analyses\n",
    "V = build_vectorizer(config=vec_config)\n",
    "V.fit(pre[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5734b916",
   "metadata": {},
   "source": [
    "    # ### Model comparison: Detailed CV scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b3fa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 9: Prepare post labels in the pre-learned class space ============================\n",
    "# - Single-label: drop unseen labels; Multi-label: fix the class order using pre classes\n",
    "if args.multilabel:\n",
    "    y_post_list = post[\"diagnosis\"].fillna(\"\").map(\n",
    "        lambda s: [t for t in re.split(r\"[|,;/]\", s) if t]\n",
    "    ).tolist()\n",
    "    Y_post = MultiLabelBinarizer(classes=classes).fit(classes).transform(y_post_list)\n",
    "else:\n",
    "    class_to_idx = {c: i for i, c in enumerate(classes)}\n",
    "    y_post_idx = post[\"diagnosis\"].map(class_to_idx).fillna(-1).astype(int)\n",
    "    keep = y_post_idx >= 0\n",
    "    dropped = (~keep).sum()\n",
    "    if dropped > 0:\n",
    "        warnings.warn(f\"Dropping {dropped} post rows with unseen labels.\")\n",
    "    post = post[keep].copy()\n",
    "    Y_post = y_post_idx[keep].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce2e610",
   "metadata": {},
   "source": [
    "Explain a bit what is happening here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcab9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 10: Evaluate best model on post split ============================================\n",
    "# - Use the fitted steps from the CV best pipeline to avoid leakage\n",
    "vec_step = best.named_steps[\"vec\"]\n",
    "clf_step = best.named_steps[\"clf\"]\n",
    "\n",
    "# Transform post text with the *trained* vectorizer\n",
    "#X_post_vec = vec_step.transform(pd.DataFrame({\"text\": post[\"text\"]}))\n",
    "X_post_text = post[\"text\"].astype(str).tolist()\n",
    "X_post_vec = vec_step.transform(X_post_text)\n",
    "#pdb.set_trace()\n",
    "\n",
    "# Get probabilities (calibrated when enabled; logistic link fallback otherwise)\n",
    "y_prob_post = (\n",
    "    clf_step.predict_proba(X_post_vec)\n",
    "    if hasattr(clf_step, \"predict_proba\")\n",
    "    else predict_proba_safe(clf_step, X_post_vec)\n",
    ")\n",
    "print(type(Y_post), getattr(Y_post, \"shape\", None), len(Y_post))\n",
    "print(type(y_prob_post), getattr(y_prob_post, \"shape\", None), len(y_prob_post))\n",
    "\n",
    "if isinstance(y_prob_post, list):\n",
    "    print(\"list length:\", len(y_prob_post))\n",
    "    print(\"first element type/shape:\", type(y_prob_post[0]), getattr(y_prob_post[0], \"shape\", None))\n",
    "metrics_post = eval_probs(Y_post, y_prob_post, classes, args.multilabel)\n",
    "with open(os.path.join(args.output_dir, \"metrics_post.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metrics_post, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c09d06c",
   "metadata": {},
   "source": [
    "Explain a bit what is happening here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a3e65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_aupr_per_class(\n",
    "    Y_true=Y_post,\n",
    "    Y_prob=y_prob_post,\n",
    "    classes=classes,\n",
    "    plots_dir=graphs_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b511705",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# === Step 11: Fairness slices metrics ======================================================\n",
    "# - soldier_flag / gender / age_group; includes false PTSD rate per slice\n",
    "slices = eval_slices(\n",
    "    post.reset_index(drop=True), Y_post, y_prob_post, classes, args.multilabel,plots_dir=graphs_dir,do_plots = False\n",
    ")\n",
    "with open(os.path.join(args.output_dir, \"slices_post.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(slices, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9444fe26",
   "metadata": {},
   "source": [
    "### Feature correlation with target (class separation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a4b9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 12: Distribution shift (drift) around top pre terms ==============================\n",
    "drift = drift_top_terms(V, pre[\"text\"], post[\"text\"], top_k=50)\n",
    "with open(os.path.join(args.output_dir, \"drift.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(drift, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66371783",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Explain a bit what is happening here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e02241",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# === Step 13: Explainability via coefficients (plain model) ================================\n",
    "# Refit a NON-calibrated model to expose coef_ cleanly; map to feature names\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# 1) Start from the CV-best pipeline params\n",
    "best_params = best.get_params()\n",
    "\n",
    "# 2) Ensure the explainability vectorizer uses the SAME hyperparams as the best pipeline\n",
    "vec_params = {k.replace(\"vec__\", \"\"): v for k, v in best_params.items() if k.startswith(\"vec__\")}\n",
    "if vec_params:\n",
    "    try:\n",
    "        V.set_params(**vec_params)\n",
    "    except Exception:\n",
    "        # Keep V as-is if params are incompatible\n",
    "        pass\n",
    "\n",
    "# 3) Build a NON-calibrated classifier\n",
    "best_clf = best.named_steps[\"clf\"]\n",
    "core_est = getattr(best_clf, \"estimator\", best_clf)\n",
    "\n",
    "# Ensure the core estimator is wrapped in OneVsRest if multilabel is enabled\n",
    "if args.multilabel:\n",
    "    if not isinstance(core_est, OneVsRestClassifier):\n",
    "        plain_clf = OneVsRestClassifier(clone(core_est))\n",
    "    else:\n",
    "        plain_clf = clone(core_est)\n",
    "else:\n",
    "    plain_clf = clone(core_est)\n",
    "\n",
    "# Copy any clf__ params if they exist\n",
    "clf_params = {k.replace(\"clf__\", \"\"): v for k, v in best_params.items() if k.startswith(\"clf__\")}\n",
    "if clf_params:\n",
    "    try:\n",
    "        plain_clf.set_params(**clf_params)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# 4) Fit explainability pipeline on all pre data\n",
    "expl_pipe = Pipeline([\n",
    "    (\"select\", ColumnSelector(\"text\")),\n",
    "    (\"vec\", V),\n",
    "    (\"clf\", plain_clf),\n",
    "])\n",
    "\n",
    "# This will now accept Y_pre as a matrix when multilabel is True\n",
    "expl_pipe.fit(pd.DataFrame({\"text\": pre[\"text\"]}), Y_pre)\n",
    "\n",
    "# 5) Extract top coefficients mapped to feature names\n",
    "# The top_coefficients function in your code already handles OneVsRestClassifier\n",
    "coef_top = top_coefficients(expl_pipe.named_steps[\"clf\"], V, classes, k=20)\n",
    "\n",
    "with open(os.path.join(args.output_dir, \"explain_top_coeffs.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(coef_top, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5914e5",
   "metadata": {},
   "source": [
    "Explain a bit what is happening here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f25134b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "# === Step 14: Optional masking robustness test =============================================\n",
    "# - Replace context-sensitive terms (e.g., חייל/מילואים) with [MASK] and re-evaluate deltas\n",
    "\n",
    "if args.mask_sensitive_test:\n",
    "    post_masked = post.copy()\n",
    "    post_masked[\"text\"] = post_masked[\"text\"].map(mask_sensitive)\n",
    "\n",
    "    X_mask_text = post_masked[\"text\"].astype(str).tolist()\n",
    "    X_mask_vec = vec_step.transform(X_mask_text)\n",
    "\n",
    "    y_prob_mask = (\n",
    "        clf_step.predict_proba(X_mask_vec)\n",
    "        if hasattr(clf_step, \"predict_proba\")\n",
    "        else predict_proba_safe(clf_step, X_mask_vec)\n",
    "    )\n",
    "\n",
    "    metrics_mask = eval_probs(Y_post, y_prob_mask, classes, args.multilabel)\n",
    "\n",
    "    delta = {}\n",
    "    for k in metrics_post:\n",
    "        if isinstance(metrics_post[k], dict):\n",
    "            continue\n",
    "        try:\n",
    "            delta[k] = float(metrics_mask[k]) - float(metrics_post[k])\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    out = {\"masked_metrics\": metrics_mask, \"delta_vs_unmasked\": delta}\n",
    "    with open(os.path.join(args.output_dir, \"masking_eval.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(out, f, ensure_ascii=False, indent=2)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py:percent",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
